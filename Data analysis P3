Data analysis P3
Reference: https://github.com/ShiChJ/DAND-QA/tree/master/Intro-DataAnalysis
pandas.to_datetime (Convert argument to datetime.)

final_month = pd.Timestamp('2018-02-01')
df_final_month = df[df['week'] >= final_month]
df_final_month.iloc[:,1:].sum().argmax() #从第一列开始取每列的合，返回最大值

# 重复数据查询<count duplicates>
sum(df.duplicated())

# 详细数据类型
type(df['fixed_acidity'][0])

# 时间转换
(1)
import numpy as np
a = np.random.random(int(1e8))
import time
start = time.time()
sum(a) / len(a)
print(time.time() - start, 'seconds')
(2)
start = time.time()
np.mean(a)
print(time.time() - start, 'seconds')

# 为红葡萄酒数据框创建颜色数组
color_red = np.repeat('red',red_df.shape[0])
将名为 ‘颜色’ 的新列设置到适当数组，将数组添加到红葡萄酒和白葡萄酒数据框中。下面的框是在红葡萄酒数据框中添加数组。
red_df['color'] = color_red
red_df.head()
The shape attribute for numpy arrays returns the dimensions of the array. If Y has n rows and m columns, 
then Y.shape is (n,m). So Y.shape[0] is n.

# 查找缺少值的合计
df.isnull().sum()

# 合并两个dataframe
df_all = df08.append(df18)

# 寻找unique值
for col in df_18.columns:
    print('{} : {}'.format(col, len(df_18[col].dropna().unique())))

# 保存新数据集，供下一段使用
df_08.to_csv('data_08.csv', index=False)

# 重命名
red_df.rename(index = str, columns = {'total_sulfur-dioxide': 'total_sulfur_dioxide'},inplace = True)

# 在 2008 数据集中用下划线和小写标签代替空格
df_08.rename(columns=lambda x: x.strip().lower().replace(" ", "_"), inplace=True)

# 将销售区域重命名为特定区域
df_08.rename(index = str, columns = {'Sales Area':'Cert Region'}, inplace = True)

# 去除空格引数指定
>>> 'www.example.com'.strip('cmowz.')
'example'

# 去除空格引数なし
>>> '     www.example.com    '.strip()
'www.example.com'

# 去除\n
>>> print '\nhello'

hello
# \nも除去される
>>> print '\nhello'.strip()
hello

# 验证是否所有列的标题都相同
(df_08.columns == df_18.columns).all()

# 从 2018 数据集中丢弃列
df_18.drop(['Stnd','Stnd Description','Underhood ID','Comb CO2'], axis=1, inplace=True)

# 检查 2008 cyl列的值数量 按各cyl检查
df_08['cyl'].value_counts()
(6 cyl)     409
(4 cyl)     283
(8 cyl)     199
(5 cyl)      48
(12 cyl)     30
(10 cyl)     14
(2 cyl)       2
(16 cyl)      1
Name: cyl, dtype: int64

# 更换数据类型(1)change type(1)
df['column'] = df['column'].astype(int)

# 更换数据类型(2)change type(to float)
1.pandas.to_numeric(arg, errors='raise', downcast=None)[source]
2.pd.to_numeric(df_08['air_pollution_score'])
Convert argument to a numeric type.

# 获取 2008 年的所有混合动力,查找带 / 的行
hb_08 = df_08[df_08['fuel'].str.contains('/')]
hb_08

# 待分割列的列表
split_columns = ['fuel', 'city_mpg', 'hwy_mpg', 'cmb_mpg',]

# 对每个数据框副本的每个列应用分割功能
for c in split_columns:
    df1[c] = df1[c].apply(lambda x: x.split("/")[0])
    df2[c] = df2[c].apply(lambda x: x.split("/")[1])
    
# 添加这两个数据框
new_rows = df1.append(df2)

# 从原始 2018 数据框中丢弃每个混合动力行
# 对 hb_18 的索引进行 Pandas 的丢弃功能，实现上述步骤
df_18.drop(hb_18.index, inplace=True)

# 将 new_rows 添加到 df_18
df_18 = df_18.append(new_rows, ignore_index=True)

# 检查是否已删除
df_18[df_18['fuel'].str.contains('/')]

# 输出dataframe的两列
df_0818 = df_combined[['model_2008','model_2018']]

# Get dataframe with all records from experiment group
experiment_df = df.query('group == "experiment"')

# Compute click through rate for experiment group
experiment_ctr = experiment_df.query('action == "enroll"').count()[0]/experiment_df.query('action == "view"').count()[0]

# Generate a random Dataframe
import pandas as pd
import numpy as np
>>> df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))
>>> df.head()
          A         B         C         D
0  0.016443 -2.318952 -0.566372 -1.028078
1 -1.051921  0.438836  0.658280 -0.175797
2 -1.243569 -0.364626 -0.215065  0.057736
3  1.768216  0.404512 -0.385604 -1.457834
4  1.072446 -1.137172  0.314194 -0.046661

# Generate a defined Dataframe
x = pd.Series(np.array([15, 4, 3, 8, 15, 22, 7, 9, 2, 3, 3, 12, 6]))

#reading_time = views.grouby(['id','group'])['duration'].mean()

#reading_time = views.grouby(['id','group'])['duration'].sum()

#在python里拟合回归线
import pandas as pd
import numpy as np
import statsmodels.api as sm
df = pd.read_csv('./house_price_area_only.csv')
df.head()
df('intercept') = 1
lm = sm.OLS(df['price'], df[['intercept', 'area']]) # ordinary least squares
results= lm.fit()
results.summary()

seaborn.pairplot(df[['area','bedrooms','bathrooms']]);
